{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "|:------------------:|:------------------------------------------------------------------:|\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        ).argmax()\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self, video_folder: str) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env_id = \"CartPole-v0\"\n",
    "env = gym.make(env_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "# 20000\n",
    "num_frames = 200000\n",
    "memory_size = 10000\n",
    "batch_size = 128\n",
    "target_update = 100\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_48804/2365843195.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_48804/3985652851.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, num_frames, plotting_interval)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;31m# if training is ready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[0mupdate_cnt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_48804/3985652851.py\u001b[0m in \u001b[0;36mupdate_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\13521\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mclip_coef_clamped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef_clamped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a3f677a77b69d4794d31f44cefe23a57cb8094311290e7ebc8599ef847ede09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
